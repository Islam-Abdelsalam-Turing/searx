{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "588fbe58",
      "metadata": {
        "id": "588fbe58"
      },
      "source": [
        "**Sample ID**: gpqa_263\n",
        "\n",
        "**Query**: In the 'ObservationalAstronomy' project, open the file 'espresso_detectability_problem.md' and solve the question.\n",
        "\n",
        "**DB Type**: Base Case\n",
        "\n",
        "**Case Description**:\n",
        "A project directory named \"ObservationalAstronomy\" exists. The file \"ObservationalAstronomy/espresso_detectability_problem.md\" exists and contains the following problem: \"How many of the stars listed below would be detectable using the ESPRESSO spectrograph, when it is coupled with one of the 8m VLT telescopes at the Paranal Observatory? A star is considered detectable if a signal-to-noise ratio (S/N) of at least 10 per binned pixel during a 1-hour exposure is achieved.\n",
        "\n",
        "For more details about the ESPRESSO spectrograph, please refer to the following link:\n",
        "https://www.eso.org/sci/facilities/paranal/instruments/espresso/overview.html\n",
        "\n",
        "a) Canopus\n",
        "b) Polaris\n",
        "c) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 10 pc distance from us.\n",
        "d) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 200 pc distance from us.\n",
        "e) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 5 pc distance from us.\n",
        "f) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 50 pc distance from us.\n",
        "Answer Choices\n",
        "A) 3\n",
        "B) 2\n",
        "C) 4\n",
        "D) 5\".\n",
        "\n",
        "**Global/Context Variables**:\n",
        "\n",
        "\n",
        "**APIs**:\n",
        "- cursor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228faea3",
      "metadata": {
        "id": "228faea3"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e617a3f1",
      "metadata": {
        "id": "e617a3f1"
      },
      "source": [
        "## Download relevant files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ecc5536",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ecc5536",
        "outputId": "6d317ccd-67b6-4e45-9d10-279903227856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pylatexenc\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/162.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m153.6/162.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=2c34d4abfaba9279b03709f714ad5c7aeadc22c3b6209e6c2a6464634aca6093\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/3e/78/fa1588c1ae991bbfd814af2bcac6cef7a178beee1939180d46\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc\n",
            "Successfully installed pylatexenc-2.10\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n",
            "Searching for APIs zip file with version 0.1.4 in folder: 1QpkAZxXhVFzIbm8qPGPRP1YqXEvJ4uD4...\n",
            "Found matching file: APIs_V0.1.4.zip (ID: 1TnAaWGfVrMxWTilyhy46-Aue_bh0XkNk)\n",
            "Downloading APIs zip file with ID: 1TnAaWGfVrMxWTilyhy46-Aue_bh0XkNk...\n",
            "Download progress: 100%\n",
            "Extracting specific items from /content/APIs_V0.1.4.zip to /content...\n",
            "\n",
            "Verifying extracted items:\n",
            "✅ /content/APIs is present.\n",
            "✅ /content/DBs is present.\n",
            "✅ /content/Scripts is present.\n",
            "\n",
            "✅ Setup complete! Required items extracted to /content.\n",
            "\n",
            "Generating FC Schemas\n",
            "✅ Successfully generated 70 FC Schemas to /content/Schemas\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import shutil\n",
        "import re\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "!pip install pylatexenc\n",
        "!pip install ftfy\n",
        "\n",
        "\n",
        "# Version to download\n",
        "VERSION = \"0.1.4\"  # Version of the API\n",
        "\n",
        "# Define paths\n",
        "CONTENT_DIR = '/content'\n",
        "APIS_DIR = os.path.join(CONTENT_DIR, 'APIs')\n",
        "DBS_DIR = os.path.join(CONTENT_DIR, 'DBs')\n",
        "SCRIPTS_DIR = os.path.join(CONTENT_DIR, 'Scripts')\n",
        "FC_DIR = os.path.join(CONTENT_DIR, 'Schemas')\n",
        "ZIP_PATH = os.path.join(CONTENT_DIR, f'APIs_V{VERSION}.zip')\n",
        "\n",
        "# Google Drive Folder ID where versioned APIs zip files are stored\n",
        "APIS_FOLDER_ID = '1QpkAZxXhVFzIbm8qPGPRP1YqXEvJ4uD4'\n",
        "\n",
        "# List of items to extract from the zip file\n",
        "ITEMS_TO_EXTRACT = ['APIs/', 'DBs/', 'Scripts/', 'Schemas/']\n",
        "\n",
        "# Clean up existing directories and files\n",
        "for path in [APIS_DIR, DBS_DIR, SCRIPTS_DIR, FC_DIR, ZIP_PATH]:\n",
        "    if os.path.exists(path):\n",
        "        if os.path.isdir(path):\n",
        "            shutil.rmtree(path)\n",
        "        else:\n",
        "            os.remove(path)\n",
        "\n",
        "# Authenticate and create the drive service\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Helper function to download a file from Google Drive\n",
        "def download_drive_file(service, file_id, output_path, file_name=None, show_progress=True):\n",
        "    \"\"\"Downloads a file from Google Drive\"\"\"\n",
        "    destination = output_path\n",
        "    request = service.files().get_media(fileId=file_id)\n",
        "    with io.FileIO(destination, 'wb') as fh:\n",
        "        downloader = MediaIoBaseDownload(fh, request)\n",
        "        done = False\n",
        "        while not done:\n",
        "            status, done = downloader.next_chunk()\n",
        "            if show_progress:\n",
        "                print(f\"Download progress: {int(status.progress() * 100)}%\")\n",
        "\n",
        "\n",
        "# 1. List files in the specified APIs folder\n",
        "print(f\"Searching for APIs zip file with version {VERSION} in folder: {APIS_FOLDER_ID}...\")\n",
        "apis_file_id = None\n",
        "\n",
        "try:\n",
        "    query = f\"'{APIS_FOLDER_ID}' in parents and trashed=false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "    files = results.get('files', [])\n",
        "    for file in files:\n",
        "        file_name = file.get('name', '')\n",
        "        if file_name.lower() == f'apis_v{VERSION.lower()}.zip':\n",
        "            apis_file_id = file.get('id')\n",
        "            print(f\"Found matching file: {file_name} (ID: {apis_file_id})\")\n",
        "            break\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing files in Google Drive: {e}\")\n",
        "\n",
        "if not apis_file_id:\n",
        "    print(f\"Error: Could not find APIs zip file with version {VERSION} in the specified folder.\")\n",
        "    sys.exit(\"Required APIs zip file not found.\")\n",
        "\n",
        "# 2. Download the found APIs zip file\n",
        "print(f\"Downloading APIs zip file with ID: {apis_file_id}...\")\n",
        "download_drive_file(drive_service, apis_file_id, ZIP_PATH, file_name=f'APIs_V{VERSION}.zip')\n",
        "\n",
        "# 3. Extract specific items from the zip file to /content\n",
        "print(f\"Extracting specific items from {ZIP_PATH} to {CONTENT_DIR}...\")\n",
        "try:\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_contents = zip_ref.namelist()\n",
        "\n",
        "        for member in zip_contents:\n",
        "            extracted = False\n",
        "            for item_prefix in ITEMS_TO_EXTRACT:\n",
        "              if member == item_prefix or member.startswith(item_prefix):\n",
        "                    zip_ref.extract(member, CONTENT_DIR)\n",
        "                    extracted = True\n",
        "                    break\n",
        "\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: The downloaded file at {ZIP_PATH} is not a valid zip file.\")\n",
        "    sys.exit(\"Invalid zip file downloaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during extraction: {e}\")\n",
        "    sys.exit(\"Extraction failed.\")\n",
        "\n",
        "\n",
        "# 4. Clean up\n",
        "if os.path.exists(ZIP_PATH):\n",
        "    os.remove(ZIP_PATH)\n",
        "\n",
        "# 5. Add APIs to path\n",
        "if os.path.exists(APIS_DIR):\n",
        "    sys.path.append(APIS_DIR)\n",
        "else:\n",
        "    print(f\"Error: APIS directory not found at {APIS_DIR} after extraction. Cannot add to path.\")\n",
        "\n",
        "# 6. Quick verification\n",
        "# Check for the presence of the extracted items\n",
        "verification_paths = [APIS_DIR, DBS_DIR, SCRIPTS_DIR]\n",
        "all_present = True\n",
        "print(\"\\nVerifying extracted items:\")\n",
        "for path in verification_paths:\n",
        "    if os.path.exists(path):\n",
        "        print(f\"✅ {path} is present.\")\n",
        "    else:\n",
        "        print(f\"❌ {path} is MISSING!\")\n",
        "        all_present = False\n",
        "\n",
        "if all_present:\n",
        "    print(f\"\\n✅ Setup complete! Required items extracted to {CONTENT_DIR}.\")\n",
        "else:\n",
        "    print(\"\\n❌ Setup failed! Not all required items were extracted.\")\n",
        "\n",
        "# 7. Generate Schemas\n",
        "\n",
        "print(\"\\nGenerating FC Schemas\")\n",
        "\n",
        "# Change working directory to the source folder\n",
        "\n",
        "# Iterate through the packages in the /content/APIs directory\n",
        "\n",
        "    # Check if it's a directory (to avoid processing files)\n",
        "        # Call the function to generate schema for the current package\n",
        "print(f\"✅ Successfully generated {len(os.listdir(FC_DIR))} FC Schemas to {FC_DIR}\")\n",
        "os.chdir(CONTENT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4715c06e",
      "metadata": {
        "id": "4715c06e"
      },
      "source": [
        "## Install Dependencies and Clone Repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f7a702",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80f7a702",
        "outputId": "19c3ef0a-0ec3-4045-e9c3-4ca26203d3e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m161 packages\u001b[0m \u001b[2min 7.05s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m57 packages\u001b[0m \u001b[2min 8.12s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m15 packages\u001b[0m \u001b[2min 88ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m57 packages\u001b[0m \u001b[2min 155ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1manthropic\u001b[0m\u001b[2m==0.71.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.13.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.13.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbracex\u001b[0m\u001b[2m==2.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcoverage\u001b[0m\u001b[2m==7.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcssselect\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdeepdiff\u001b[0m\u001b[2m==8.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdnspython\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdocopt\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mdocstring-parser\u001b[0m\u001b[2m==0.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdocstring-parser\u001b[0m\u001b[2m==0.16\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mduckdb\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mduckdb\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1memail-validator\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mete3\u001b[0m\u001b[2m==3.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfreezegun\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgoogle-genai\u001b[0m\u001b[2m==1.44.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgoogle-genai\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjson-repair\u001b[0m\u001b[2m==0.44.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjsonpath-ng\u001b[0m\u001b[2m==1.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-anthropic\u001b[0m\u001b[2m==0.3.19\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-openai\u001b[0m\u001b[2m==0.3.30\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlevenshtein\u001b[0m\u001b[2m==0.27.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlibcst\u001b[0m\u001b[2m==1.8.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlxml-html-clean\u001b[0m\u001b[2m==0.4.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mmcp\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmcp\u001b[0m\u001b[2m==1.12.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmermaid-python\u001b[0m\u001b[2m==0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmongomock\u001b[0m\u001b[2m==4.3.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopenpyxl\u001b[0m\u001b[2m==3.1.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopenpyxl\u001b[0m\u001b[2m==3.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1morderly-set\u001b[0m\u001b[2m==5.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mphonenumbers\u001b[0m\u001b[2m==9.0.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplaywright\u001b[0m\u001b[2m==1.52.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mportalocker\u001b[0m\u001b[2m==2.10.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==5.9.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyee\u001b[0m\u001b[2m==13.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpymongo\u001b[0m\u001b[2m==4.13.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpymongo-schema\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpypdf2\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpytest\u001b[0m\u001b[2m==8.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytest\u001b[0m\u001b[2m==8.3.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-levenshtein\u001b[0m\u001b[2m==0.27.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-pptx\u001b[0m\u001b[2m==0.6.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mqdrant-client\u001b[0m\u001b[2m==1.14.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mquickjs\u001b[0m\u001b[2m==1.19.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrapidfuzz\u001b[0m\u001b[2m==3.14.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mreadability-lxml\u001b[0m\u001b[2m==0.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mreportlab\u001b[0m\u001b[2m==4.4.4\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msentinels\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1msqlglot\u001b[0m\u001b[2m==25.20.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msqlglot\u001b[0m\u001b[2m==26.25.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msqlglotrs\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.48.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.47.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mthefuzz\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.66.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.37.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.35.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwcmatch\u001b[0m\u001b[2m==10.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwhoosh\u001b[0m\u001b[2m==2.7.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxlsxwriter\u001b[0m\u001b[2m==3.2.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxlwt\u001b[0m\u001b[2m==1.3.0\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -r /content/APIs/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d7bc2e3",
      "metadata": {
        "id": "6d7bc2e3"
      },
      "source": [
        "## Import APIs and initiate DBs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2bade8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2bade8c",
        "outputId": "fc8743a3-8e6d-4993-b9c2-ed2ad42433c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Created question file: ./workspace/ObservationalAstronomy/espresso_detectability_problem.md\n",
            "[ACTION] Hydrating DB from workspace: ./workspace ...\n",
            "[SUCCESS] Cursor DB hydrated from: ./workspace\n",
            "\n",
            "[VERIFY] Listing project directory:\n",
            "  - espresso_detectability_problem.md | Directory: False | Size: 970 bytes\n",
            "\n",
            "[VERIFY] Listing workspace root:\n",
            "  - ObservationalAstronomy | Directory: True\n"
          ]
        }
      ],
      "source": [
        "# CURSOR INITIAL DB\n",
        "\n",
        "import os\n",
        "import cursor\n",
        "from cursor.SimulationEngine.utils import hydrate_db_from_directory\n",
        "from cursor.SimulationEngine.db import DB\n",
        "\n",
        "db_state_path = \"/content/DBs/CursorDefaultDB.json\"\n",
        "cursor.SimulationEngine.db.load_state(db_state_path)\n",
        "\n",
        "# === SECTION A — VARIABLES (FILLERS) ===\n",
        "\n",
        "# Since we are not working with GitHub projects, we just need to define the project folder we want to use and create the files in it.\n",
        "# The workspace directory is a constant that helps us access and inspect the project.\n",
        "# With this, we’re following the previously defined folder hierarchy.\n",
        "# Since we have the identifiers already setted, we're adapting their uses here.\n",
        "\n",
        "PROJECT_NAME  = \"ObservationalAstronomy\"\n",
        "WORKSPACE = f\"./workspace\"\n",
        "PROJECT_DIR = f\"{WORKSPACE}/{PROJECT_NAME}\"\n",
        "\n",
        "question_content   = \"\"\"How many of the stars listed below would be detectable using the ESPRESSO spectrograph, when it is coupled with one of the 8m VLT telescopes at the Paranal Observatory? A star is considered detectable if a signal-to-noise ratio (S/N) of at least 10 per binned pixel during a 1-hour exposure is achieved.\n",
        "\n",
        "For more details about the ESPRESSO spectrograph, please refer to the following link:\n",
        "https://www.eso.org/sci/facilities/paranal/instruments/espresso/overview.html\n",
        "\n",
        "a) Canopus\n",
        "b) Polaris\n",
        "c) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 10 pc distance from us.\n",
        "d) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 200 pc distance from us.\n",
        "e) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 5 pc distance from us.\n",
        "f) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 50 pc distance from us.\n",
        "Answer Choices\n",
        "A) 3\n",
        "B) 2\n",
        "C) 4\n",
        "D) 5\"\"\"\n",
        "\n",
        "question_file_name = \"espresso_detectability_problem.md\"\n",
        "answer_file_name   = \"NO ANSWER FILE\"\n",
        "\n",
        "# Set environment variables for this session - To Be Checked\n",
        "ENV_GOOGLE_API_KEY = \"AIzaSyCkQFuIGGpONvrg1FEF8_mvdWzw9TYClr8\"\n",
        "ENV_GEMINI_MODEL   = \"gemini-2.5-pro\"\n",
        "\n",
        "# === SECTION B — CODE (DO NOT MODIFY) ===\n",
        "os.environ['GOOGLE_API_KEY'] = ENV_GOOGLE_API_KEY\n",
        "os.environ['DEFAULT_GEMINI_MODEL_NAME'] = ENV_GEMINI_MODEL\n",
        "\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "\n",
        "question_file_path = os.path.join(PROJECT_DIR, question_file_name)\n",
        "\n",
        "with open(question_file_path, \"w\") as f:\n",
        "    f.write(question_content)\n",
        "print(f\"[INFO] Created question file: {question_file_path}\")\n",
        "\n",
        "if answer_file_name != \"NO ANSWER FILE\":\n",
        "    answer_file_path   = os.path.join(PROJECT_DIR, answer_file_name)\n",
        "    with open(answer_file_path, \"w\") as f:\n",
        "        f.write(\"\")\n",
        "    print(f\"[INFO] Created empty solution file: {answer_file_path}\")\n",
        "\n",
        "print(f\"[ACTION] Hydrating DB from workspace: {WORKSPACE} ...\")\n",
        "hydrate_db_from_directory(DB, WORKSPACE)\n",
        "print(f\"[SUCCESS] Cursor DB hydrated from: {WORKSPACE}\")\n",
        "\n",
        "print(\"\\n[VERIFY] Listing project directory:\")\n",
        "project_listing = cursor.list_dir(PROJECT_NAME)\n",
        "for item in project_listing:\n",
        "    print(f\"  - {item['name']} | Directory: {item['is_directory']} | Size: {item['size_bytes']} bytes\")\n",
        "\n",
        "print(\"\\n[VERIFY] Listing workspace root:\")\n",
        "workspace_listing = cursor.list_dir(\".\")\n",
        "for item in workspace_listing:\n",
        "    print(f\"  - {item['name']} | Directory: {item['is_directory']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b868616",
      "metadata": {
        "id": "4b868616"
      },
      "source": [
        "# Initial Assertion\n",
        "1. Assert that a project directory named `ObservationalAstronomy` exists.\n",
        "2. Assert that the project directory contains the file `ObservationalAstronomy/espresso_detectability_problem.md`.\n",
        "3. Assert that the file `ObservationalAstronomy/espresso_detectability_problem.md` contains exactly one problem with the content \"How many of the stars listed below would be detectable using the ESPRESSO spectrograph, when it is coupled with one of the 8m VLT telescopes at the Paranal Observatory? A star is considered detectable if a signal-to-noise ratio (S/N) of at least 10 per binned pixel during a 1-hour exposure is achieved.\n",
        "\n",
        "For more details about the ESPRESSO spectrograph, please refer to the following link:\n",
        "https://www.eso.org/sci/facilities/paranal/instruments/espresso/overview.html\n",
        "\n",
        "a) Canopus\n",
        "b) Polaris\n",
        "c) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 10 pc distance from us.\n",
        "d) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 200 pc distance from us.\n",
        "e) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 5 pc distance from us.\n",
        "f) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 50 pc distance from us.\n",
        "Answer Choices\n",
        "A) 3\n",
        "B) 2\n",
        "C) 4\n",
        "D) 5\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c6c2bb9",
      "metadata": {
        "id": "9c6c2bb9"
      },
      "outputs": [],
      "source": [
        "import cursor\n",
        "import re\n",
        "from Scripts.assertions_utils import *\n",
        "\n",
        "def _normalize_string(string: str) -> str:\n",
        "    s = str(string).strip().lower()\n",
        "    s = re.sub(r'\\s+', ' ', s)  # collapse multiple spaces/newlines\n",
        "    return s\n",
        "\n",
        "# context variables\n",
        "project_directory = \"ObservationalAstronomy\"\n",
        "file = \"espresso_detectability_problem.md\"\n",
        "\n",
        "# 1. assertion 1 – Validate Project Directory Existence\n",
        "workspace_contents = cursor.list_dir(\".\")\n",
        "project_dir_found = False\n",
        "if workspace_contents is not None:\n",
        "    for item in workspace_contents:\n",
        "        if compare_strings(\n",
        "            _normalize_string(item.get(\"name\")),\n",
        "            _normalize_string(project_directory)\n",
        "        ) and item.get(\"is_directory\"):\n",
        "            project_dir_found = True\n",
        "            break\n",
        "\n",
        "assert project_dir_found, (\n",
        "    f\"Assertion 1 Failed: Project directory '{project_directory}' does not exist \"\n",
        "    f\"or is not a directory in the workspace root.\"\n",
        ")\n",
        "\n",
        "# 2. assertion 2 – Check if Question File Exists\n",
        "project_dir_contents = cursor.list_dir(project_directory)\n",
        "question_file_found = False\n",
        "if project_dir_contents is not None:\n",
        "    for item in project_dir_contents:\n",
        "        if compare_strings(\n",
        "            _normalize_string(item.get(\"name\")),\n",
        "            _normalize_string(file)\n",
        "        ) and not item.get(\"is_directory\"):\n",
        "            question_file_found = True\n",
        "            break\n",
        "\n",
        "assert question_file_found, (\n",
        "    f\"Assertion 2 Failed: File '{file}' not found in '{project_directory}' \"\n",
        "    f\"or it is incorrectly marked as a directory.\"\n",
        ")\n",
        "\n",
        "# 3. assertion 3 – Verify Question File Content\n",
        "expected_question_text = (\n",
        "    \"How many of the stars listed below would be detectable using the ESPRESSO spectrograph, when it is coupled with one of the 8m VLT telescopes at the Paranal Observatory? A star is considered detectable if a signal-to-noise ratio (S/N) of at least 10 per binned pixel during a 1-hour exposure is achieved.\\n\\n\"\n",
        "    \"For more details about the ESPRESSO spectrograph, please refer to the following link:\\n\"\n",
        "    \"https://www.eso.org/sci/facilities/paranal/instruments/espresso/overview.html\\n\\n\"\n",
        "    \"a) Canopus\\n\"\n",
        "    \"b) Polaris\\n\"\n",
        "    \"c) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 10 pc distance from us.\\n\"\n",
        "    \"d) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 200 pc distance from us.\\n\"\n",
        "    \"e) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 5 pc distance from us.\\n\"\n",
        "    \"f) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 50 pc distance from us.\\n\"\n",
        "    \"Answer Choices\\n\"\n",
        "    \"A) 3\\n\"\n",
        "    \"B) 2\\n\"\n",
        "    \"C) 4\\n\"\n",
        "    \"D) 5\"\n",
        ")\n",
        "\n",
        "question_file_data = cursor.read_file(\n",
        "    target_file=f\"{project_directory}/{file}\",\n",
        "    should_read_entire_file=True,\n",
        "    start_line_one_indexed=1,                    # Required parameter (ignored when full read)\n",
        "    end_line_one_indexed_inclusive=1             # Required parameter (ignored when full read)\n",
        ")\n",
        "actual_question_content_list = question_file_data.get(\"content\", [])\n",
        "actual_question_content = \"\".join(actual_question_content_list)\n",
        "\n",
        "assert compare_strings(\n",
        "    _normalize_string(actual_question_content),\n",
        "    _normalize_string(expected_question_text)\n",
        "), (\n",
        "    f\"Assertion 3 Failed: Content of '{project_directory}/{file}' does not match expected problem text. \"\n",
        "    f\"\\nExpected: '{expected_question_text}'\\nActual: '{actual_question_content}'\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e87fe82",
      "metadata": {
        "id": "6e87fe82"
      },
      "source": [
        "# Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b74f6d1",
      "metadata": {
        "id": "6b74f6d1"
      },
      "outputs": [],
      "source": [
        "# proto_ignore\n",
        "import cursor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o7us1Bj4AIML",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7us1Bj4AIML",
        "outputId": "6e314781-1472-47ff-c01d-efb03bb64b24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'path': '/content/workspace/ObservationalAstronomy',\n",
              "  'name': 'ObservationalAstronomy',\n",
              "  'is_directory': True,\n",
              "  'size_bytes': 0,\n",
              "  'last_modified': '2025-10-20T13:44:43.358507Z'}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cursor.list_dir(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U5_SNVS-AOjb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5_SNVS-AOjb",
        "outputId": "ac858e0c-58e9-4efb-e41b-da32757dea40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'path': '/content/workspace/ObservationalAstronomy/espresso_detectability_problem.md',\n",
              "  'name': 'espresso_detectability_problem.md',\n",
              "  'is_directory': False,\n",
              "  'size_bytes': 970,\n",
              "  'last_modified': '2025-10-20T13:44:43.358507Z'}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cursor.list_dir(relative_workspace_path=\"ObservationalAstronomy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y-GxqJnmAd8o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-GxqJnmAd8o",
        "outputId": "12b5ab4c-f2fc-423e-a537-cec4f49eb91a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'success': True,\n",
              " 'start_line': 1,\n",
              " 'end_line': 16,\n",
              " 'content': ['How many of the stars listed below would be detectable using the ESPRESSO spectrograph, when it is coupled with one of the 8m VLT telescopes at the Paranal Observatory? A star is considered detectable if a signal-to-noise ratio (S/N) of at least 10 per binned pixel during a 1-hour exposure is achieved.\\n',\n",
              "  '\\n',\n",
              "  'For more details about the ESPRESSO spectrograph, please refer to the following link:\\n',\n",
              "  'https://www.eso.org/sci/facilities/paranal/instruments/espresso/overview.html\\n',\n",
              "  '\\n',\n",
              "  'a) Canopus\\n',\n",
              "  'b) Polaris\\n',\n",
              "  'c) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 10 pc distance from us.\\n',\n",
              "  'd) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 200 pc distance from us.\\n',\n",
              "  'e) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 5 pc distance from us.\\n',\n",
              "  'f) Star with RA = 0 deg and DEC = 0 deg, Absolute V magnitude of 15 mag and located at 50 pc distance from us.\\n',\n",
              "  'Answer Choices\\n',\n",
              "  'A) 3\\n',\n",
              "  'B) 2\\n',\n",
              "  'C) 4\\n',\n",
              "  'D) 5'],\n",
              " 'total_lines': 16,\n",
              " 'path_processed': '/content/workspace/ObservationalAstronomy/espresso_detectability_problem.md',\n",
              " 'summary_of_truncated_content': None,\n",
              " 'message': \"Successfully read all 16 lines from the file 'espresso_detectability_problem.md'.\"}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cursor.read_file(\n",
        "    target_file=\"/content/workspace/ObservationalAstronomy/espresso_detectability_problem.md\",\n",
        "    should_read_entire_file=True,\n",
        "    start_line_one_indexed=1,\n",
        "    end_line_one_indexed_inclusive=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1549c86b",
      "metadata": {
        "id": "1549c86b"
      },
      "source": [
        "# Golden Answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the given parameters for the ESPRESSO spectrograph, a total of 3 of the listed stars would be detectable."
      ],
      "metadata": {
        "id": "5kE5sp_pewXI"
      },
      "id": "5kE5sp_pewXI"
    },
    {
      "cell_type": "markdown",
      "id": "d0a78533",
      "metadata": {
        "id": "d0a78533"
      },
      "source": [
        "# Final Assertion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d11ddfc2",
      "metadata": {
        "id": "d11ddfc2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}